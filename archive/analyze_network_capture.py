#!/usr/bin/env python3
"""
Analyse approfondie de la capture r√©seau pour extraire les vraies donn√©es Foodles.
"""

import json
from pathlib import Path
import re
from datetime import datetime

def analyze_api_calls():
    """Analyse les fichiers captur√©s"""
    
    capture_dir = Path("network_capture")
    if not capture_dir.exists():
        print("‚ùå Aucun fichier de capture trouv√© dans network_capture/")
        return
    
    # Trouver le fichier le plus r√©cent
    json_files = list(capture_dir.glob("api_calls_*.json"))
    if not json_files:
        print("‚ùå Aucun fichier api_calls_*.json trouv√©")
        return
    
    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
    print(f"üìÇ Analyse de: {latest_file.name}")
    print("=" * 80)
    
    with open(latest_file) as f:
        api_calls = json.load(f)
    
    # Cat√©goriser les appels
    foodles_calls = []
    third_party_calls = []
    
    for call in api_calls:
        url = call.get('url', '')
        if 'app.foodles.co' in url or 'foodles' in url.lower():
            foodles_calls.append(call)
        else:
            third_party_calls.append(call)
    
    print(f"\nüìä R√âSUM√â DE LA CAPTURE")
    print(f"   Total appels: {len(api_calls)}")
    print(f"   ‚Ä¢ Foodles: {len(foodles_calls)}")
    print(f"   ‚Ä¢ Tiers (analytics, monitoring): {third_party_calls.__len__()}")
    
    print(f"\nüéØ APPELS FOODLES TROUV√âS:")
    print("-" * 80)
    
    unique_urls = {}
    for call in foodles_calls:
        url = call['url']
        method = call['method']
        key = f"{method} {url}"
        
        if key not in unique_urls:
            unique_urls[key] = {
                'method': method,
                'url': url,
                'count': 0,
                'has_post_data': bool(call.get('post_data')),
                'headers': call.get('headers', {})
            }
        unique_urls[key]['count'] += 1
    
    for i, (key, info) in enumerate(unique_urls.items(), 1):
        print(f"\n{i}. {info['method']} {info['url']}")
        print(f"   Appel√© {info['count']} fois")
        if info['has_post_data']:
            print(f"   ‚ö†Ô∏è  Contient des donn√©es POST")
        
        # Afficher les headers int√©ressants
        headers = info['headers']
        interesting_headers = ['cookie', 'authorization', 'x-csrf-token', 'content-type']
        for h in interesting_headers:
            if h in headers or h.lower() in [k.lower() for k in headers.keys()]:
                print(f"   Header: {h} pr√©sent")
    
    # Analyser les services tiers
    print(f"\n\nüîç SERVICES TIERS D√âTECT√âS:")
    print("-" * 80)
    
    third_party_domains = {}
    for call in third_party_calls:
        url = call['url']
        # Extraire le domaine
        match = re.search(r'https?://([^/]+)', url)
        if match:
            domain = match.group(1)
            if domain not in third_party_domains:
                third_party_domains[domain] = {
                    'count': 0,
                    'endpoints': set()
                }
            third_party_domains[domain]['count'] += 1
            # Extraire le path
            path_match = re.search(r'https?://[^/]+(/[^?]*)', url)
            if path_match:
                third_party_domains[domain]['endpoints'].add(path_match.group(1))
    
    for domain, info in sorted(third_party_domains.items(), key=lambda x: x[1]['count'], reverse=True):
        print(f"\n‚Ä¢ {domain}")
        print(f"  {info['count']} appels")
        if len(info['endpoints']) <= 5:
            for endpoint in sorted(info['endpoints']):
                print(f"    ‚Üí {endpoint}")
    
    # Rechercher des donn√©es POST int√©ressantes
    print(f"\n\nüíæ DONN√âES POST ANALYS√âES:")
    print("-" * 80)
    
    for call in foodles_calls:
        if call.get('post_data'):
            print(f"\nüì§ POST {call['url']}")
            post_data = call['post_data']
            if isinstance(post_data, str):
                # Essayer de parser comme JSON
                try:
                    data = json.loads(post_data)
                    print(f"   Type: JSON")
                    print(f"   Cl√©s: {list(data.keys())[:10]}")
                except:
                    print(f"   Type: Texte ({len(post_data)} caract√®res)")
                    print(f"   D√©but: {post_data[:200]}")
    
    print(f"\n\nüí° CONCLUSION:")
    print("=" * 80)
    print("""
Les captures r√©seau montrent que Foodles utilise une architecture Next.js avec:
1. Server-Side Rendering (SSR) - Les donn√©es sont dans le HTML initial
2. React Server Components (RSC) - Format propri√©taire

‚ùå Aucune API REST classique n'a √©t√© trouv√©e pour:
   - Liste des produits du frigo
   - Ajout au panier
   - Commandes

üéØ SOLUTIONS POSSIBLES:

A. REVERSE ENGINEERING DU FORMAT RSC
   ‚Ä¢ Les r√©ponses HTML contiennent les donn√©es dans un format RSC
   ‚Ä¢ Notre parser RSC peut extraire ces donn√©es
   ‚Ä¢ Mais c'est fragile et peut changer

B. INTERCEPTION DES ACTIONS CLIENT-SIDE
   ‚Ä¢ Utiliser Playwright pour simuler des clics
   ‚Ä¢ Intercepter les requ√™tes XHR/Fetch qui se d√©clenchent
   ‚Ä¢ N√©cessite une connexion active

C. API BACKEND (SI ELLE EXISTE)
   ‚Ä¢ Possible que Foodles ait une API interne non document√©e
   ‚Ä¢ N√©cessiterait d'inspecter le code JavaScript de l'app
   ‚Ä¢ Ou d'utiliser les DevTools Network pendant l'utilisation r√©elle

Recommandation: Analyser le code JavaScript de l'app pour trouver
les vraies APIs utilis√©es pour les actions (ajouter au panier, etc.)
    """)


def analyze_responses():
    """Analyse les r√©ponses captur√©es"""
    capture_dir = Path("network_capture")
    response_files = list(capture_dir.glob("responses_*.json"))
    
    if not response_files:
        print("‚ùå Aucun fichier de r√©ponses trouv√©")
        return
    
    latest_file = max(response_files, key=lambda p: p.stat().st_mtime)
    print(f"\n\nüì• ANALYSE DES R√âPONSES")
    print(f"   Fichier: {latest_file.name}")
    print("=" * 80)
    
    with open(latest_file) as f:
        responses = json.load(f)
    
    print(f"   Total r√©ponses captur√©es: {len(responses)}")
    
    # Analyser chaque r√©ponse
    for i, response in enumerate(responses, 1):
        url = response.get('url', '')
        status = response.get('status_code', 0)
        content_type = response.get('content_type', '')
        body = response.get('body', '')
        
        if 'foodles' in url.lower():
            print(f"\n{i}. {url}")
            print(f"   Status: {status}")
            print(f"   Content-Type: {content_type}")
            print(f"   Taille: {len(body)} caract√®res")
            
            if 'json' in content_type.lower():
                try:
                    data = json.loads(body)
                    print(f"   Type: JSON valide")
                    print(f"   Cl√©s racine: {list(data.keys())[:10]}")
                except:
                    pass


if __name__ == "__main__":
    print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë     üîç ANALYSE APPROFONDIE DE LA CAPTURE R√âSEAU FOODLES             ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
    
    analyze_api_calls()
    analyze_responses()
    
    print("\n" + "=" * 80)
    print("‚úÖ Analyse termin√©e!")
    print("=" * 80 + "\n")

# ğŸ•µï¸ Guide d'utilisation de l'intercepteur rÃ©seau

## ğŸ“‹ PrÃ©requis

```bash
# Playwright est dÃ©jÃ  installÃ©
# Les navigateurs sont tÃ©lÃ©chargÃ©s
```

## ğŸš€ Lancement de l'intercepteur

### Option 1: Mode automatique (sans login manuel)

```bash
python network_interceptor.py
```

Le script va:
1. Ouvrir un navigateur Chrome visible
2. Naviguer vers app.foodles.co
3. **Vous devez vous connecter manuellement**
4. Le script capturera automatiquement toutes les requÃªtes rÃ©seau
5. Visiter plusieurs pages (frigo, cantine, compte, etc.)
6. Sauvegarder tous les rÃ©sultats

### Option 2: Mode headless (arriÃ¨re-plan)

Modifiez dans [network_interceptor.py](network_interceptor.py) ligne 95:
```python
browser = p.chromium.launch(headless=True)  # True pour invisible
```

## ğŸ“Š Ce qui sera capturÃ©

### RequÃªtes rÃ©seau
- **Toutes les URLs** visitÃ©es
- **MÃ©thodes HTTP** (GET, POST, PUT, DELETE)
- **Headers** de requÃªte
- **DonnÃ©es POST** (si applicable)

### RÃ©ponses API
- **Status codes** (200, 404, etc.)
- **Headers** de rÃ©ponse
- **Body JSON** complet pour les APIs
- **Contenu texte** pour les pages HTML

## ğŸ“ Fichiers gÃ©nÃ©rÃ©s

Dans le dossier `network_capture/`:

```
network_capture/
â”œâ”€â”€ requests_20260130_HHMMSS.json     # Toutes les requÃªtes
â”œâ”€â”€ responses_20260130_HHMMSS.json    # Toutes les rÃ©ponses
â”œâ”€â”€ api_calls_20260130_HHMMSS.json    # Uniquement les appels API
â””â”€â”€ report_20260130_HHMMSS.json       # Rapport rÃ©sumÃ©
```

## ğŸ” Analyse des rÃ©sultats

### Trouver les endpoints API

```bash
# Lire le rapport
cat network_capture/report_*.json | jq '.unique_endpoints'

# Chercher des endpoints spÃ©cifiques
grep -i "api.*product" network_capture/api_calls_*.json

# Voir les rÃ©ponses JSON
cat network_capture/responses_*.json | jq '.[].body' | head -50
```

### En Python

```python
import json

# Charger le rapport
with open('network_capture/report_TIMESTAMP.json') as f:
    report = json.load(f)

print(f"Endpoints trouvÃ©s: {len(report['unique_endpoints'])}")
for endpoint in report['unique_endpoints']:
    print(f"  - {endpoint}")

# Charger les rÃ©ponses
with open('network_capture/responses_TIMESTAMP.json') as f:
    responses = json.load(f)

# Filtrer les rÃ©ponses avec des donnÃ©es JSON
json_responses = [r for r in responses if isinstance(r.get('body'), dict)]
print(f"\nRÃ©ponses JSON: {len(json_responses)}")
```

## ğŸ¯ StratÃ©gies de capture

### 1. Capture passive (recommandÃ© pour dÃ©buter)
- Laisser le navigateur ouvert
- Se connecter manuellement
- Naviguer normalement sur le site
- Le script capture tout

### 2. Capture interactive
- Cliquer sur les produits
- Ajouter au panier
- Passer une commande (test)
- Toutes les requÃªtes API seront capturÃ©es

### 3. Capture ciblÃ©e
Modifiez `pages_to_visit` dans le script:
```python
pages_to_visit = [
    ('Frigo', '/canteen/fridge'),
    ('Menu du jour', '/canteen/menu'),
    ('Historique commandes', '/account/orders'),
    # Ajoutez vos pages
]
```

## ğŸ”§ Personnalisation

### Ajouter des interactions

Dans [network_interceptor.py](network_interceptor.py), ajoutez aprÃ¨s la ligne 144:

```python
# Cliquer sur un produit spÃ©cifique
page.click('text=Coca-Cola')
page.wait_for_timeout(2000)

# Ajouter au panier
page.click('button:has-text("Ajouter")')
page.wait_for_timeout(2000)

# Scroll infini
for i in range(5):
    page.evaluate('window.scrollBy(0, 500)')
    page.wait_for_timeout(1000)
```

### Filtrer les requÃªtes capturÃ©es

Modifiez la condition ligne 33:

```python
# Capturer uniquement certaines URLs
if 'foodles.co' in request.url and '/api/' in request.url:
    self.api_calls.append(req_data)
```

## ğŸ› DÃ©pannage

### Le navigateur ne s'ouvre pas
```bash
# RÃ©installer Chromium
/home/a154355/git/perso/foodle/.venv/bin/playwright install chromium --force
```

### Timeout errors
Augmentez les timeouts dans le script:
```python
page.goto(url, wait_until='networkidle', timeout=60000)  # 60 secondes
```

### Pas de requÃªtes capturÃ©es
- VÃ©rifiez que vous Ãªtes connectÃ©
- Naviguez manuellement pour dÃ©clencher des requÃªtes
- Regardez la console du navigateur (F12)

## ğŸ’¡ Astuces

### 1. Capturer uniquement les APIs produits
```python
if 'product' in request.url.lower() or 'fridge' in request.url.lower():
    print(f"ğŸ¯ PRODUIT: {request.url}")
    self.api_calls.append(req_data)
```

### 2. Sauvegarder les cookies
```python
cookies = context.cookies()
with open('foodles_cookies.json', 'w') as f:
    json.dump(cookies, f)
```

### 3. RÃ©utiliser une session
```python
# Charger les cookies sauvegardÃ©s
with open('foodles_cookies.json') as f:
    cookies = json.load(f)
context.add_cookies(cookies)
```

## ğŸ“– Exemples d'utilisation

### Capturer les produits du frigo
```bash
python network_interceptor.py
# Puis dans le navigateur:
# 1. Connectez-vous
# 2. Allez sur /canteen/fridge
# 3. Scrollez pour charger tous les produits
# 4. Attendez 10-15 secondes
# 5. Le script sauvegarde automatiquement
```

### Analyser les rÃ©sultats
```python
import json

with open('network_capture/api_calls_*.json') as f:
    api_calls = json.load(f)

# Trouver les endpoints liÃ©s aux produits
product_endpoints = [
    call for call in api_calls 
    if 'product' in call['url'].lower()
]

print(f"Endpoints produits: {len(product_endpoints)}")
for endpoint in product_endpoints[:5]:
    print(f"  {endpoint['method']} {endpoint['url']}")
```

## ğŸ“ Prochaines Ã©tapes

AprÃ¨s avoir capturÃ© les vraies requÃªtes API:

1. **Identifier les patterns d'URL**
   ```
   https://app.foodles.co/api/v1/products?canteen=2051
   https://app.foodles.co/api/cart/add
   ```

2. **Extraire les headers nÃ©cessaires**
   - Authorization
   - X-CSRF-Token
   - Content-Type

3. **RÃ©pliquer les appels dans foodles_api.py**
   ```python
   def get_products_real(self, canteen_id: int):
       url = f"{self.BASE_URL}/api/v1/products"
       params = {'canteen': canteen_id}
       return self.session.get(url, params=params).json()
   ```

4. **Tester et valider**

## âš ï¸ Notes importantes

- **Respecter les CGU** de Foodles
- **Ne pas surcharger** le serveur avec trop de requÃªtes
- **ProtÃ©ger vos tokens** (ne jamais les commit)
- **Utiliser headless=False** au dÃ©but pour debugger

---

**PrÃªt?** Lancez `python network_interceptor.py` et dÃ©couvrez les vraies API! ğŸš€
